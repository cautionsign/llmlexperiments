# Experiment 24 — Dance Dance Revolution

I am really into multimodal ai — or perhaps multimodal in general. I have always been into multimodal but I just called it mapping or visualization or sonification. I am also into diagramming.

This morning I was reading Robert Ducan’s The H.D. Book and whether or not H.D. was an imagist poet. Imagism reacted against romanticism and looked for simplicity in describing visual images. Sort of multimodal!

Here is a link to H.D.’s poem [Heat](https://poets.org/poem/heat). It does feel a bit romantic.

I was still on my dance kick from a few days before so I asked

![](https://miro.medium.com/v2/resize:fit:1400/1*uqPMinrzANToywBUaKEvQA.png)

>write code inspired by yvonne rainer

https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2Fu2I5JbhOhSg%3Ffeature%3Doembed&display_name=YouTube&url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3Du2I5JbhOhSg&image=https%3A%2F%2Fi.ytimg.com%2Fvi%2Fu2I5JbhOhSg%2Fhqdefault.jpg&key=a19fcc184b9711e1b4764040d3dc5c07&type=text%2Fhtml&schema=youtube

I think this is kind of amazing.

I see chat as a tool for all sorts of directions, instructions, and choreography.

But what is missing is detail — resultion. An instruction set is like a lossy and compressed audio recording.

the code — [https://github.com/msrobot0/llmlexperiments/](https://github.com/msrobot0/llmlexperiments/)